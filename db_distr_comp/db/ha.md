# 高可用

DolphinDB
分布式架构提供数据、元数据和客户端的高可用方案，即使数据库节点发生故障，数据库仍然可以正常运作，保证业务不会中断。

## 数据高可用

在分布式环境下，为保证数据读写服务的高可用，DolphinDB
会把同一个分区的数据同时写入到集群中的多个不同的节点上。同一个分区在不同节点上的数据拷贝称为副本（Replica）。DolphinDB
集群支持处理千万级以上的分区数据，为了保证数据的强一致性和事务 ACID 特性，它采用了轻量、高效且可行的两阶段提交协议（Two-phase
Commit）来管理数据副本之间的一致性。这种方式确保了即使某个节点上的数据出现损坏，仍然可以通过访问其他节点上的副本数据来持续提供数据服务，从而保证了服务的不中断性。同时，针对数据损坏或其它原因导致的副本数据不一致的情况，系统会通过
recovery 机制将数据恢复到一致状态。

在生产环境中，一般把副本个数设置为大于2，可以保证数据的高可用。

## 元数据高可用

DolphinDB 控制节点存储的元数据记录了分区分布的节点，版本信息等。在一个集群中可以部署多个控制节点，通过元数据冗余来保证元数据服务不中断。DolphinDB 采用
Raft 协议保证控制节点的高可用性。一个集群中的所有控制节点组成一个 Raft 组，一个 Raft 组中只有一个 Leader，其他都是 Follower。只有
Leader 与数据节点进行交互，当它收到接收数据节点的请求后，先写入本地日志文件中，并向集群中的每一个 Follower
发送同步日志的请求，当日志同步到大多数节点后告诉 Follower 提交日志。Follower 接收并持久化 Leader 同步的日志，在 Leader
告知提交后，提交日志，这样就能保证 Leader 和 Follower上元数据的强一致性。如果当前 Leader 宕机，系统会立即选举出新的 Leader
来提供元数据服务。Raft
组能够容忍小于半数的控制节点宕机，只要宕机的控制节点少于半数，集群仍然可以提供服务，因此可以保证控制节点上元数据的一致性。例如包含三个控制节点的集群可以容忍一个控制节点出现故障，包含五个控制节点的集群可以容忍两个控制节点出现故障。要设置元数据高可用，集群中控制节点的数量至少为3个，同时需要设置数据高可用，即副本数必须大于1。

## 客户端高可用

DolphinDB API 提供了强大的自动重连和切换机制，旨在确保与数据节点/计算节点的交互始终保持高可用性。使用 DolphinDB API 与 DolphinDB
的数据节点/计算节点进行交互时，如果连接的节点宕机，API 会尝试自动重新建立连接，若尝试重连失败，API
会自动连接到集群中其他可用的数据节点/计算节点，以保证客户端与服务器之间连接的稳定性。而且切换过程对用户来说是完全透明的，用户不会察觉到当前连接的节点已经发生了切换。

